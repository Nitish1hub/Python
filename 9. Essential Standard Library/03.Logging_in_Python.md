# Logging in Python - Professional Debugging and Monitoring

## Table of Contents
1. [Introduction - Why Logging Matters](#introduction---why-logging-matters)
2. [Print vs Logging](#print-vs-logging)
3. [Basic Logging](#basic-logging)
4. [Log Levels](#log-levels)
5. [Configuring Logging](#configuring-logging)
6. [Logging to Files](#logging-to-files)
7. [Log Formatting](#log-formatting)
8. [Multiple Handlers](#multiple-handlers)
9. [Logger Hierarchy](#logger-hierarchy)
10. [Best Practices](#best-practices)
11. [Real-Life Practical Examples](#real-life-practical-examples)
12. [Common Mistakes](#common-mistakes)13. [Summary](#summary)
14. [Practice Exercises](#practice-exercises)
15. [What's Next?](#whats-next)

---

## Introduction - Why Logging Matters

**Scenario:** Your application crashes in production. How do you debug?

**With print statements:**
- ‚ùå Output mixed with normal output
- ‚ùå No way to control verbosity
- ‚ùå Not saved anywhere
- ‚ùå Can't filter by severity
- ‚ùå Crashes might not show anything

**With proper logging:**
- ‚úÖ Organized by severity (ERROR, WARNING, INFO)
- ‚úÖ Saved to files automatically
- ‚úÖ Can be turned on/off per module
- ‚úÖ Includes timestamps
- ‚úÖ Professional debugging tool

**Real-World Analogy:**
- **Print:** Shouting information randomly
- **Logging:** Organized journal with timestamps and categories

**In this blog, you'll learn:**
- Professional logging practices
- Log levels and when to use them
- Logging to files and console
- Formatting log messages
- Building production-ready logging

---

## Print vs Logging

### The Print Problem

```python
def process_order(order_id):
    print(f"Processing order {order_id}")
    
    # ... complex logic ...
    
    if error:
        print(f"ERROR: Order {order_id} failed!")
    
    print(f"Order {order_id} completed")
```

**Problems:**
- Can't easily turn off debug prints
- No timestamps
- Can't save to file
- Output mixes with normal program output
- No severity levels

### The Logging Solution

```python
import logging

logger = logging.getLogger(__name__)

def process_order(order_id):
    logger.info(f"Processing order {order_id}")
    
    # ... complex logic ...
    
    if error:
        logger.error(f"Order {order_id} failed!")
    
    logger.info(f"Order {order_id} completed")
```

**Benefits:**
- ‚úÖ Can control what's shown
- ‚úÖ Automatic timestamps
- ‚úÖ Can log to files
- ‚úÖ Different severity levels
- ‚úÖ Production-ready

---

## Basic Logging

### Hello World of Logging

```python
import logging

# Simple logging
logging.debug("This is a debug message")
logging.info("This is an info message")
logging.warning("This is a warning message")
logging.error("This is an error message")
logging.critical("This is a critical message")

# Output (default shows WARNING and above):
# WARNING:root:This is a warning message
# ERROR:root:This is an error message
# CRITICAL:root:This is a critical message
```

### Basic Configuration

```python
import logging

# Configure logging
logging.basicConfig(level=logging.DEBUG)

logging.debug("Now debug messages show!")  # This will appear
logging.info("Info messages too!")         # This will appear
```

---

## Log Levels

**Define: Log Level** - Severity/importance of a log message.

### Log Level Hierarchy

| Level | Numeric Value | When to Use | Example |
|-------|---------------|-------------|---------|
| **DEBUG** | 10 | Detailed debugging info | Variable values, execution flow |
| **INFO** | 20 | General informational messages | "Server started", "User logged in" |
| **WARNING** | 30 | Warning about potential problems | "Disk space low", "Deprecated API" |
| **ERROR** | 40 | Error occurred, but app continues | "Failed to save file", "API timeout" |
| **CRITICAL** | 50 | Serious error, app may crash | "Database connection lost", "Out of memory" |

### When to Use Each Level

```python
import logging

logging.basicConfig(level=logging.DEBUG)

# DEBUG - Detailed diagnostic info
numbers = [1, 2, 3, 4, 5]
logging.debug(f"Processing {len(numbers)} items: {numbers}")

# INFO - Normal operation confirmation
logging.info("Application started successfully")
logging.info("User 'john' logged in")

# WARNING - Something unexpected but not an error
logging.warning("Configuration file not found, using defaults")
logging.warning("Disk space below 10%")

# ERROR - Something failed but app continues
try:
    result = 10 / 0
except ZeroDivisionError:
    logging.error("Division by zero occurred")

# CRITICAL - Serious error, app might crash
try:
    connect_to_database()
except ConnectionError:
    logging.critical("Cannot connect to database! Application cannot continue")
```

### Setting Log Level

```python
import logging

# Show WARNING and above (default)
logging.basicConfig(level=logging.WARNING)

logging.debug("Not shown")    # Hidden
logging.info("Not shown")     # Hidden
logging.warning("Shown")      # Visible
logging.error("Shown")        # Visible

# Show DEBUG and above (everything)
logging.basicConfig(level=logging.DEBUG)

logging.debug("Now shown")    # Visible
logging.info("Also shown")    # Visible
```

---

## Configuring Logging

### Basic Configuration

```python
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(levelname)s - %(message)s'
)

logging.debug("Debug message")
logging.info("Info message")

# Output:
# DEBUG - Debug message
# INFO - Info message
```

### Configuration Options

```python
import logging

logging.basicConfig(
    level=logging.INFO,                    # Minimum level to log
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  # Format
    datefmt='%Y-%m-%d %H:%M:%S',          # Date format
    filename='app.log',                    # Log to file
    filemode='w'                          # 'w' = overwrite, 'a' = append
)

logging.info("Application started")

# Output in app.log:
# 2024-01-15 14:30:45 - root - INFO - Application started
```

---

## Logging to Files

### Single File Logging

```python
import logging

# Log to file
logging.basicConfig(
    filename='application.log',
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

logging.info("Application started")
logging.error("An error occurred")

# Creates application.log with:
# 2024-01-15 14:30:45,123 - INFO - Application started
# 2024-01-15 14:30:46,456 - ERROR - An error occurred
```

### Append vs Overwrite

```python
import logging

# Overwrite file each time (filemode='w')
logging.basicConfig(
    filename='app.log',
    filemode='w',  # Starts fresh each run
    level=logging.INFO
)

# Append to file (filemode='a' or default)
logging.basicConfig(
    filename='app.log',
    filemode='a',  # Keeps previous logs
    level=logging.INFO
)
```

### Both Console and File

```python
import logging

# Setup logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# Console handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_format = logging.Formatter('%(levelname)s - %(message)s')
console_handler.setFormatter(console_format)

# File handler
file_handler = logging.FileHandler('app.log')
file_handler.setLevel(logging.DEBUG)
file_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(file_format)

# Add handlers
logger.addHandler(console_handler)
logger.addHandler(file_handler)

# Use logger
logger.debug("Debug info (file only)")
logger.info("Info message (both)")
logger.error("Error message (both)")
```

---

## Log Formatting

### Format String Attributes

| Attribute | Description | Example |
|-----------|-------------|---------|
| `%(asctime)s` | Timestamp | 2024-01-15 14:30:45,123 |
| `%(name)s` | Logger name | my_module |
| `%(levelname)s` | Log level | INFO, ERROR |
| `%(message)s` | Log message | User logged in |
| `%(filename)s` | Source file | app.py |
| `%(lineno)d` | Line number | 42 |
| `%(funcName)s` | Function name | process_data |
| `%(pathname)s` | Full path | /path/to/app.py |

### Common Formats

```python
import logging

# Simple format
logging.basicConfig(
    format='%(levelname)s: %(message)s'
)
logging.info("Simple")
# Output: INFO: Simple

# Detailed format
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logging.info("Detailed")
# Output: 2024-01-15 14:30:45 - root - INFO - Detailed

# Debug format (with file and line)
logging.basicConfig(
    format='%(asctime)s [%(levelname)s] %(filename)s:%(lineno)d - %(message)s'
)
logging.debug("Debug info")
# Output: 2024-01-15 14:30:45,123 [DEBUG] app.py:15 - Debug info

# Production format
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logging.error("Production error")
# Output: 2024-01-15 14:30:45 - root - ERROR - [app.py:20] - Production error
```

---

## Multiple Handlers

### Different Handlers for Different Purposes

```python
import logging

logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# Console handler - shows INFO and above
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(
    logging.Formatter('%(levelname)s: %(message)s')
)

# File handler - saves DEBUG and above
file_handler = logging.FileHandler('debug.log')
file_handler.setLevel(logging.DEBUG)
file_handler.setFormatter(
    logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
)

# Error file handler - saves ERROR and above only
error_handler = logging.FileHandler('errors.log')
error_handler.setLevel(logging.ERROR)
error_handler.setFormatter(
    logging.Formatter('%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')
)

# Add all handlers
logger.addHandler(console_handler)
logger.addHandler(file_handler)
logger.addHandler(error_handler)

# Test
logger.debug("Debug message")  # Only in debug.log
logger.info("Info message")    # Console + debug.log
logger.error("Error message")  # Console + debug.log + errors.log
```

---

## Logger Hierarchy

### Creating Named Loggers

```python
import logging

# Create loggers for different modules
database_logger = logging.getLogger('myapp.database')
api_logger = logging.getLogger('myapp.api')
auth_logger = logging.getLogger('myapp.auth')

# Configure
logging.basicConfig(level=logging.INFO)

# Use them
database_logger.info("Connected to database")
api_logger.warning("API rate limit approaching")
auth_logger.error("Authentication failed")

# Output:
# INFO:myapp.database:Connected to database
# WARNING:myapp.api:API rate limit approaching
# ERROR:myapp.auth:Authentication failed
```

### Best Practice Pattern

```python
# In each module file
import logging

# Use __name__ to automatically name logger after module
logger = logging.getLogger(__name__)

def my_function():
    logger.info("Function called")
    logger.debug(f"Processing with __name__={__name__}")
```

---

## Real-Life Practical Examples

### Example 1: Application with Logging

```python
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class DataProcessor:
    def __init__(self):
        self.processed_count = 0
        logger.info("DataProcessor initialized")
    
    def process_file(self, filename):
        """Process a data file"""
        logger.info(f"Starting to process {filename}")
        
        try:
            with open(filename, 'r') as f:
                data = f.read()
                logger.debug(f"Read {len(data)} characters from {filename}")
                
                # Simulate processing
                self.processed_count += 1
                logger.info(f"Successfully processed {filename}")
                
        except FileNotFoundError:
            logger.error(f"File not found: {filename}")
            raise
        except Exception as e:
            logger.critical(f"Unexpected error processing {filename}: {e}")
            raise

# Usage
processor = DataProcessor()
try:
    processor.process_file('data.txt')
except Exception:
    logger.exception("Failed to process file")  # Includes traceback
```

### Example 2: Web API with Logging

```python
import logging
from datetime import datetime

# Setup logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('api.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class APIServer:
    def __init__(self):
        self.request_count = 0
        logger.info("API Server initialized")
    
    def handle_request(self, endpoint, user_id):
        """Handle API request"""
        self.request_count += 1
        request_id = f"REQ-{self.request_count}"
        
        logger.info(f"[{request_id}] Request to {endpoint} from user {user_id}")
        
        try:
            # Simulate processing
            if endpoint == "/error":
                raise ValueError("Invalid endpoint")
            
            logger.debug(f"[{request_id}] Processing request...")
            response = {"status": "success", "data": "result"}
            logger.info(f"[{request_id}] Request completed successfully")
            return response
            
        except ValueError as e:
            logger.error(f"[{request_id}] Validation error: {e}")
            return {"status": "error", "message": str(e)}
        except Exception as e:
            logger.critical(f"[{request_id}] Unexpected error: {e}")
            return {"status": "error", "message": "Internal server error"}

# Usage
api = APIServer()
api.handle_request("/users", "user123")
api.handle_request("/error", "user456")
```

### Example 3: Database Operations with Logging

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='database.log'
)

logger = logging.getLogger(__name__)

class Database:
    def __init__(self, connection_string):
        self.connection_string = connection_string
        self.connected = False
        logger.info(f"Database object created for {connection_string}")
    
    def connect(self):
        """Connect to database"""
        logger.info("Attempting database connection...")
        try:
            # Simulate connection
            self.connected = True
            logger.info("‚úÖ Database connection successful")
            return True
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {e}")
            return False
    
    def execute_query(self, query):
        """Execute database query"""
        if not self.connected:
            logger.warning("Attempted query without connection")
            return None
        
        logger.debug(f"Executing query: {query[:50]}...")  # Log first 50 chars
        
        try:
            # Simulate query execution
            result = []  # Simulated result
            logger.info(f"Query executed successfully, {len(result)} rows returned")
            return result
        except Exception as e:
            logger.error(f"Query execution failed: {e}")
            logger.debug(f"Failed query: {query}")
            raise

# Usage
db = Database("postgresql://localhost/mydb")
db.connect()
db.execute_query("SELECT * FROM users")
```

### Example 4: Rotating Log Files

```python
import logging
from logging.handlers import RotatingFileHandler

# Create logger
logger = logging.getLogger('my_app')
logger.setLevel(logging.INFO)

# Rotating file handler - creates new file when size limit reached
handler = RotatingFileHandler(
    'app.log',
    maxBytes=1024*1024,  # 1MB
    backupCount=5        # Keep 5 backup files
)

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# Log messages
for i in range(1000):
    logger.info(f"Log message {i}")

# Creates: app.log, app.log.1, app.log.2, app.log.3, app.log.4, app.log.5
```

### Example 5: Time-based Rotating Logs

```python
import logging
from logging.handlers import TimedRotatingFileHandler

# Create logger
logger = logging.getLogger('my_app')
logger.setLevel(logging.INFO)

# Timed rotating handler - creates new file daily
handler = TimedRotatingFileHandler(
    'app.log',
    when='midnight',  # Rotate at midnight
    interval=1,       # Every 1 day
    backupCount=7     # Keep 7 days of logs
)

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

logger.info("This will be in today's log file")

# Creates: app.log, app.log.2024-01-14, app.log.2024-01-13, etc.
```

---

## Common Mistakes

### Mistake 1: Using Root Logger in Libraries

```python
# ‚ùå Wrong - affects all loggers
import logging
logging.info("Library message")

# ‚úÖ Correct - use named logger
import logging
logger = logging.getLogger(__name__)
logger.info("Library message")
```

### Mistake 2: Configuring Multiple Times

```python
# ‚ùå Wrong - basicConfig only works once
import logging
logging.basicConfig(level=logging.DEBUG)
logging.basicConfig(level=logging.INFO)  # This has no effect!

# ‚úÖ Correct - configure once at application start
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Mistake 3: Expensive String Formatting

```python
import logging

data = list(range(10000))

# ‚ùå Wrong - formats even if not logged!
logging.debug("Data: " + str(data))  # Always creates string!

# ‚úÖ Correct - uses lazy formatting
logging.debug("Data: %s", data)  # Only formats if logged

# ‚úÖ Also correct - f-string (Python 3.6+)
logging.debug(f"Data: {data}")  # But still evaluates
```

### Mistake 4: Not Logging Exceptions Properly

```python
# ‚ùå Wrong - loses traceback
try:
    risky_operation()
except Exception as e:
    logging.error(f"Error: {e}")  # No traceback!

# ‚úÖ Correct - includes traceback
try:
    risky_operation()
except Exception as e:
    logging.exception("Error occurred")  # Includes full traceback
    # OR
    logging.error("Error occurred", exc_info=True)
```

### Mistake 5: Mixing Print and Logging

```python
# ‚ùå Wrong - inconsistent
def process():
    print("Starting...")  # Using print
    logging.info("Processing")  # And logging
    print("Done!")

# ‚úÖ Correct - use logging only
def process():
    logging.info("Starting...")
    logging.info("Processing")
    logging.info("Done!")
```

---

## Best Practices

### 1. Use Named Loggers

```python
# ‚úÖ Always use __name__
import logging
logger = logging.getLogger(__name__)
```

### 2. Configure Once at Application Start

```python
# main.py
import logging

def setup_logging():
    """Configure logging once at application start"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('app.log'),
            logging.StreamHandler()
        ]
    )

if __name__ == '__main__':
    setup_logging()
    # Rest of application
```

### 3. Log at Appropriate Levels

```python
logger.debug("Detailed state information")  # Development
logger.info("Normal operations")            # Production info
logger.warning("Something unexpected")      # Potential issues
logger.error("Error occurred")              # Actual errors
logger.critical("System failure")           # Critical failures
```

### 4. Include Context in Logs

```python
# ‚úÖ Good - includes context
logger.info(f"User {user_id} logged in from {ip_address}")
logger.error(f"Failed to process order {order_id}: {error_message}")
```

### 5. Use Exception Logging

```python
# ‚úÖ Always use exception() for caught exceptions
try:
    risky_operation()
except Exception:
    logger.exception("Operation failed")  # Includes traceback
```

---

## Summary

### Key Concepts

**üìå Why Logging?**
- Better than print statements
- Professional debugging tool
- Saves to files automatically
- Organized by severity
- Can be controlled per module

**üìå Log Levels**
- DEBUG - Detailed diagnostics
- INFO - General information
- WARNING - Potential issues
- ERROR - Errors occurred
- CRITICAL - Serious failures

**üìå Configuration**
- `basicConfig()` for simple setup
- Handlers for complex scenarios
- Formatters control message format
- Multiple handlers for different outputs

**üìå Best Practices**
- Use named loggers with `__name__`
- Configure once at start
- Log at appropriate levels
- Include context in messages
- Use `exception()` for errors

---

## Practice Exercises

### Exercise 1: Basic Logger Setup
**Task:** Create a simple logging setup that logs to both console and file.

### Exercise 2: Function Tracer
**Task:** Write a decorator that logs when functions are called and when they return.

```python
@log_function_calls
def calculate(x, y):
    return x + y
# Should log: "Calling calculate(x=5, y=3)" and "calculate returned 8"
```

### Exercise 3: Error Logger
**Task:** Create a function that safely executes operations and logs all errors.

### Exercise 4: Module-specific Loggers
**Task:** Create a multi-module application with different loggers for each module.

### Exercise 5: Log File Analyzer
**Task:** Write a script that reads a log file and counts errors, warnings, and info messages.

### Exercise 6: Performance Logger
**Task:** Create a context manager that logs execution time of code blocks.

```python
with log_performance("Database query"):
    # code here
# Should log: "Database query took 0.123 seconds"
```

### Exercise 7: Log Cleaner
**Task:** Write a function that deletes log files older than N days.

### Exercise 8: Structured Logger
**Task:** Create a logger that outputs JSON format for easy parsing.

### Exercise 9: Email Alert Logger
**Task:** Create a custom handler that sends emails for CRITICAL errors.

### Exercise 10: Application Logger
**Task:** Build a complete application with proper logging throughout.

---

## What's Next?

**Congratulations!** You've learned professional logging in Python!

### Next Topics

**In the next blog, you'll learn:**
- Collections module
- Advanced data structures
- defaultdict, Counter, namedtuple
- deque and ChainMap

### Building on This

Logging is essential for:
- **Production applications** - Monitoring and debugging
- **Web services** - Request tracking
- **Data processing** - Pipeline monitoring
- **System administration** - Automated monitoring

**Keep logging! It's a professional's best friend!** üìùüîç

